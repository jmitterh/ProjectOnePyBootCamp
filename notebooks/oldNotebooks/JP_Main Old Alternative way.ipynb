{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import pprint as pprint\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to update the config file with your API key\n",
    "from config import api_key\n",
    "from config import api_id\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.adzuna.com/v1/api/jobs/us/search/\"\n",
    "#have to create iteration to get all pages of data\n",
    "pagetest = \"1\"\n",
    "api_details =\"?\" + \"app_id=\" + api_id + \"&app_key=\" + api_key\n",
    "# Build query URL\n",
    "query_url = url + pagetest + api_details\n",
    "query_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_response = requests.get(query_url)\n",
    "data_json = data_response.json()\n",
    "type(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pages = [str(x) for x in range(1,1001)]\n",
    "\n",
    "\n",
    "title = []\n",
    "company_name = []\n",
    "location = []\n",
    "post_created = []\n",
    "category = []\n",
    "lat = []\n",
    "lng = []\n",
    "\n",
    "num = 0\n",
    "nested_num = 0\n",
    "\n",
    "for page in pages:\n",
    "        response = requests.get(url + page + api_details).json()\n",
    "        num += 1 \n",
    "        for index_num in range(10):\n",
    "            try:\n",
    "                title.append(response['results'][index_num]['title'])\n",
    "                company_name.append(response['results'][index_num]['company']['display_name'])\n",
    "                location.append(response['results'][index_num]['location']['display_name'])\n",
    "                post_created.append(response['results'][index_num]['created'])\n",
    "                category.append(response['results'][index_num]['category']['label'])\n",
    "                lat.append(response['results'][index_num]['latitude'])\n",
    "                lng.append(response['results'][index_num]['longitude'])\n",
    "                nested_num += 1\n",
    "            except KeyError:\n",
    "                if len(title) > len(lng):\n",
    "                    title.pop(-1)\n",
    "                    if len(company_name) > len(title):\n",
    "                        company_name.pop(-1)\n",
    "                        if len(location) > len(company_name):\n",
    "                            location.pop(-1)\n",
    "                            if len(post_created) > len(location):\n",
    "                                post_created.pop(-1)\n",
    "                                if len(category) > len(post_created):\n",
    "                                    category.pop(-1)\n",
    "                                    if len(lat) > len(category):\n",
    "                                        lat.pop(-1)\n",
    "                                        \n",
    "                if len(lng) == len(lat) and len(lng) == len(category) and len(lng) == len(post_created) and len(lng) == len(location) and len(lng) == len(company_name) and len(lng) == len(title):\n",
    "                    print(f'Missing attribute within column for Job Post on page {num} . Removed Job Post Row ...')\n",
    "                    \n",
    "        print(f\"page {num} completed. Iterrated through {nested_num} job postings \")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking list to see if they are the same length\n",
    "len(title)\n",
    "len(company_name)\n",
    "len(location)\n",
    "len(post_created)\n",
    "len(category)\n",
    "# # #lat has \n",
    "len(lat)\n",
    "len(lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_posting_dict = {\n",
    "    \n",
    "    'Title':title,\n",
    "    'Company Name':company_name,\n",
    "    'Location':location,\n",
    "    'Job Post Created':post_created,\n",
    "    'Category':category,\n",
    "    'Lat':lat,\n",
    "    'Lng':lng\n",
    "}\n",
    "\n",
    "test_job_posting_df = pd.DataFrame(job_posting_dict)\n",
    "test_job_posting_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to a CSV file\n",
    "test_job_posting_df.to_csv('./Resources/test_data_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing to remove appending\n",
    "cities = [\"Hamburg\", \"Linz\", \"Salzburg\", \"Vienna\"]\n",
    "cities.pop(-1)\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way to get data using json_normalize\n",
    "#LINK: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.json_normalize.html\n",
    "\n",
    "pages_test = [str(x) for x in range(1,101)]\n",
    "\n",
    "counter = 0\n",
    "# Build query URL\n",
    "data_pages_df=pd.DataFrame()\n",
    "\n",
    "for page_num in pages_test:\n",
    "    response = requests.get(url + page_num + api_details).json()\n",
    "    \n",
    "    #create a df to store the normalized page that has the job postings\n",
    "    normalized_page = json_normalize(response['results'])\n",
    "    \n",
    "    #add normalized data into a df\n",
    "    data_page_df=pd.DataFrame(normalized_page)\n",
    "    \n",
    "    #add the url column to df incase an error occurs you know what page you were on\n",
    "    data_page_df['query_url'] = 'page number ' + page_num\n",
    "    \n",
    "    #append to a new df so each page can be safed\n",
    "    data_pages_df =data_pages_df.append(data_page_df)\n",
    "    \n",
    "    counter += 1\n",
    "    print(f\"Page {page_num} iteration complete\")\n",
    "    \n",
    "print(f'total rows iterated | {counter * 10}')   \n",
    "      \n",
    "#data_pages_df=drop.na((latitude))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save alternative way\n",
    "data_pages_df.to_csv('./Resources/normalized_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up data for Alternative way\n",
    "#data_pages_df=drop.na((latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the saved df\n",
    "filepath = os.path.join(\".\",\"Resources\", \"test_data_10000.csv\")\n",
    "filepath\n",
    "\n",
    "read_file = pd.read_csv(filepath)\n",
    "read_file.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.configure(api_key= gkey) # Fill in with your API key\n",
    "job_data_copy = read_file.copy()\n",
    "\n",
    "lat = job_data_copy['Lat']\n",
    "lng = job_data_copy['Lng']\n",
    "cat = job_data_copy['Unnamed: 0']\n",
    "\n",
    "\n",
    "cat = cat.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = job_data_copy[['Lat', 'Lng']]\n",
    "fig = gmaps.figure(map_type='TERRAIN')\n",
    "\n",
    "\n",
    "\n",
    "locations_layer = gmaps.symbol_layer(\n",
    "    locations, fill_color='red', stroke_color='green', scale=1\n",
    ")\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(locations_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charr = job_data_copy['Category'].unique()\n",
    "charr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category\n",
    "index_cat = job_data_copy.set_index(['Category'])\n",
    "cat = index_cat.loc[\"Sales Jobs\"] \n",
    "healthcare = cat[['Lat', 'Lng']]\n",
    "healthcare\n",
    "\n",
    "# for c in range(len(charr)):\n",
    "#     flag = index_cat.loc[c]\n",
    "#     arm = flag[['Lat','Lng']]\n",
    "    \n",
    "job_data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
